{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f409cc4",
   "metadata": {},
   "source": [
    "## Importing Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "737e0b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "from typing import List, Dict, Set, Any\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d234d",
   "metadata": {},
   "source": [
    "## Utitlity Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6905df6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_conversations(directory_path):\n",
    "    \"\"\"\n",
    "    Load all conversation files from the specified directory.Supported formats are JSON and YAML.\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing conversation files.\n",
    "    Returns:\n",
    "        list of dict: List of conversations with 'call_id' and 'conversation' keys.\n",
    "    \"\"\"\n",
    "    all_convos = []\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(('.json', '.yml', '.yaml')):\n",
    "            try:\n",
    "                with open(os.path.join(directory_path, filename), 'r', encoding='utf-8') as f:\n",
    "                    if filename.endswith('.json'):\n",
    "                        convo = json.load(f)\n",
    "                    else:\n",
    "                        convo = yaml.safe_load(f)\n",
    "                all_convos.append({'call_id': os.path.splitext(filename)[0], 'conversation': convo})\n",
    "            except Exception as e:\n",
    "                print(f\"Failed loading {filename}: {e}\")\n",
    "    return all_convos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1cbf36",
   "metadata": {},
   "source": [
    "## Regex Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a08140",
   "metadata": {},
   "source": [
    "### Modules For Regex Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b078908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_profanity_patterns(profanity_file):\n",
    "    \"\"\"\n",
    "    Load profanity words from a file and compile regex patterns for each word.\n",
    "    Args:\n",
    "        profanity_file (str): Path to the file containing profanity words.\n",
    "    Returns:\n",
    "        list: List of tuples (word, compiled_regex).\n",
    "    \"\"\"\n",
    "    with open(profanity_file, 'r', encoding='utf-8') as f:\n",
    "        words = [line.strip() for line in f if line.strip()]\n",
    "    patterns = [(word, re.compile(rf'\\b{re.escape(word)}\\b', re.IGNORECASE)) for word in words]\n",
    "    return patterns\n",
    "\n",
    "\n",
    "\n",
    "def detect_profanity_in_conversations_regex(conversations, profanity_patterns):\n",
    "    \"\"\"\n",
    "    Detects profanity in conversations.\n",
    "    Args:\n",
    "        conversations (list): List of conversation dicts with 'call_id' and 'conversation'.\n",
    "        profanity_patterns (list): List of tuples (word, compiled_regex).\n",
    "\n",
    "    Returns:\n",
    "    dict with call_id mapping to detected profanity info:\n",
    "    {\n",
    "        'call_id': {\n",
    "            'Agent': set([...profane words...]),\n",
    "            'Customer': set([...profane words...])\n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    profanity_results = {}\n",
    "\n",
    "    for call in tqdm(conversations, desc=\"Processing calls\"):\n",
    "        call_id = call['call_id']\n",
    "        utterances = call['conversation']\n",
    "        agent_profanities = set()\n",
    "        customer_profanities = set()\n",
    "\n",
    "        for utterance in utterances:\n",
    "            text = utterance.get('text', '')\n",
    "            speaker = utterance.get('speaker', '').lower()\n",
    "\n",
    "            for word, pattern in profanity_patterns:\n",
    "                if pattern.search(text):\n",
    "                    if speaker == 'agent':\n",
    "                        agent_profanities.add(word)\n",
    "                    elif speaker == 'customer' or speaker == 'borrower':\n",
    "                        customer_profanities.add(word)\n",
    "\n",
    "        profanity_results[call_id] = {\n",
    "            'Agent': agent_profanities,\n",
    "            'Customer': customer_profanities\n",
    "        }\n",
    "\n",
    "    return profanity_results\n",
    "\n",
    "\n",
    "def search_profanity_calls_regex(conversations_dir, profanity_file):\n",
    "    \"\"\"\n",
    "    Searches for profanity in conversations and returns calls with detected profanity.\n",
    "    Args:\n",
    "        conversations_dir (str): Directory containing conversation JSON files.\n",
    "        profanity_file (str): Path to the file containing profanity words.\n",
    "    Returns:\n",
    "        dict: Calls with detected profanity and the profane words found.\n",
    "    \"\"\"\n",
    "    conversations = load_conversations(conversations_dir)\n",
    "    profanity_patterns = load_profanity_patterns(profanity_file)\n",
    "    results = detect_profanity_in_conversations_regex(conversations, profanity_patterns)\n",
    "\n",
    "    # Filter only calls with detected profanity and include the profane words found\n",
    "    profane_calls = {\n",
    "        call_id: profanities \n",
    "        for call_id, profanities in results.items()\n",
    "        if profanities['Agent'] or profanities['Customer']\n",
    "    }\n",
    "\n",
    "    return profane_calls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e402477e",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db3e6598",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing calls: 100%|██████████| 250/250 [00:02<00:00, 116.24it/s]\n",
      "100%|██████████| 42/42 [00:00<00:00, 43875.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call ID: 87e28dae-2c70-4122-9452-6ec82164fab2\n",
      "  Agent profane words: ['damn']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 80e5fe02-ec03-4ca5-902a-fdf38e6b7b8a\n",
      "  Agent profane words: ['american']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 3e6dde01-1a46-42b4-92dd-0a211185e660\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['damn', 'hell']\n",
      "\n",
      "Call ID: 89d28c5a-f0da-41e9-a93e-0a749c20189c\n",
      "  Agent profane words: ['crap', 'damn', 'hell', 'shit']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: d7bbea61-d739-43fb-a198-ced1b59f9491\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['assholes', 'fuck', 'hell', 'shit']\n",
      "\n",
      "Call ID: 9505f0e7-5404-4f50-a497-35a9e899197c\n",
      "  Agent profane words: ['crap', 'damn', 'hell', 'sick']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: d071bb49-40f8-4bae-8c6d-cfc0d4a011d5\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['bullshit', 'crap', 'damn', 'hell', 'stupid']\n",
      "\n",
      "Call ID: 8598c6d9-a767-4120-af0a-5490357c72f3\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['crap', 'damn', 'hell', 'idiot']\n",
      "\n",
      "Call ID: b70866a2-2f46-4784-992b-74d6dc60806e\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['ass', 'damn', 'hell', 'pissing', 'screw', 'shit']\n",
      "\n",
      "Call ID: 216fd3c8-1a80-484d-8792-464771794d9e\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['ass', 'hell']\n",
      "\n",
      "Call ID: 4f05aaff-585f-485f-90a1-60d027ec6e46\n",
      "  Agent profane words: ['ass', 'damn', 'hell', 'shit']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: ab6ec93c-09e1-4b88-8777-574ceb28cd05\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['crap', 'damn', 'hell', 'screw', 'stupid']\n",
      "\n",
      "Call ID: 52ddb4a0-0599-4e18-a961-ac4b67da8d5e\n",
      "  Agent profane words: ['hell']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 50abe040-847c-47e1-962f-a00d7ff2cfe4\n",
      "  Agent profane words: ['crap', 'damn']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: bf973b43-76ec-41a6-af68-a3b4bc4b69b3\n",
      "  Agent profane words: ['damn', 'hell', 'shit']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: b8628a31-ef89-4218-b2a2-3058dbc4b106\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['crap', 'damn', 'hell', 'screw']\n",
      "\n",
      "Call ID: 9a6cb7d2-c697-43a0-8cad-4194dfb44c92\n",
      "  Agent profane words: ['damn', 'shit']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: d3ee9bf9-cf64-468a-83da-fac5c6fb7a41\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['bigger', 'damn', 'goddamn', 'hell', 'screw', 'stupid']\n",
      "\n",
      "Call ID: 708878fa-108e-4c22-b7bf-1d5c38227087\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['crap', 'hell', 'screw', 'sick']\n",
      "\n",
      "Call ID: 5e231fa2-03d8-4e70-9918-da45193472a9\n",
      "  Agent profane words: ['damn', 'hell', 'sob']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: e835306a-d904-4271-8a11-5a50ce98ed90\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['crap', 'damn', 'hell']\n",
      "\n",
      "Call ID: 3e77de75-66b9-4b74-a993-1c25b6850bc9\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['bullshit', 'crap', 'dead', 'hell']\n",
      "\n",
      "Call ID: c67274cc-d920-467a-80cc-476c9dd280d4\n",
      "  Agent profane words: ['ass', 'dumbass', 'hell', 'shit']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 29489f77-b8e0-462c-9286-9216d59890f1\n",
      "  Agent profane words: ['damn', 'harder', 'shit']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 928acb70-fa80-4532-a0c0-2234bf236e17\n",
      "  Agent profane words: ['hell']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 8ae8018c-15b3-46f6-9713-f956505735ec\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['crap', 'hell']\n",
      "\n",
      "Call ID: 584fd5cd-adaa-4315-bf67-ad56d02d135e\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['crap', 'hell']\n",
      "\n",
      "Call ID: e0a8f9d2-92d6-4093-bb97-82182c6e850f\n",
      "  Agent profane words: ['damn', 'hell', 'shit']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 972a9eec-e801-459f-9cfa-997f7c42ebad\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['crap', 'damn', 'hell', 'stupid']\n",
      "\n",
      "Call ID: a76b5b3b-4e50-4e54-9a9e-9bbf6454f743\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['bullshit', 'damn', 'hell']\n",
      "\n",
      "Call ID: 20690906-b8d4-40c5-8474-9127c47b1299\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['damn', 'hell']\n",
      "\n",
      "Call ID: 2f279983-ea96-4c10-a09d-4b607de21a38\n",
      "  Agent profane words: ['crap', 'damn', 'hell']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 214c92cc-3141-404d-8224-c1b05acc345c\n",
      "  Agent profane words: ['crap', 'hell']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 2ea925db-df94-4d9b-bd72-6c227742569d\n",
      "  Agent profane words: ['remains']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: ecb08af4-0279-4178-a062-b82de0c701fb\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['hell']\n",
      "\n",
      "Call ID: 966d60ed-9111-4e44-876d-6fcc3d78773e\n",
      "  Agent profane words: ['ass', 'hell', 'shit']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 23091fb3-8e07-4d4c-8575-227e3467e73a\n",
      "  Agent profane words: ['ass', 'hell']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: 04bec80f-8614-484b-8ba2-831ff9dd03ef\n",
      "  Agent profane words: ['crap', 'damn', 'hell']\n",
      "  Customer profane words: []\n",
      "\n",
      "Call ID: b155951b-086d-4f20-8fb5-de3e42253ce6\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['damn', 'hell', 'screw']\n",
      "\n",
      "Call ID: d6a3e0da-171f-4744-ba2b-7298f2604e7f\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['ass', 'crap', 'hell', 'screw']\n",
      "\n",
      "Call ID: 6ca65973-5d6f-4ae8-824d-691263af7c22\n",
      "  Agent profane words: []\n",
      "  Customer profane words: ['disturbed']\n",
      "\n",
      "Call ID: f5f05257-aaa0-4194-b84c-36339c4e0659\n",
      "  Agent profane words: ['ass', 'bullshit', 'hell', 'screw']\n",
      "  Customer profane words: []\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conversations_directory = '../data/All_Conversations/'\n",
    "profanity_wordlist = '../data/bad-words.txt'\n",
    "\n",
    "calls_with_profanity = search_profanity_calls_regex(conversations_directory, profanity_wordlist)\n",
    "\n",
    "for call_id, profanities in tqdm(calls_with_profanity.items()):\n",
    "    print(f\"Call ID: {call_id}\")\n",
    "    print(f\"  Agent profane words: {sorted(profanities['Agent'])}\")\n",
    "    print(f\"  Customer profane words: {sorted(profanities['Customer'])}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c815d7",
   "metadata": {},
   "source": [
    "## LLM Prompt System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d69ea228",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api_key = os.getenv('GROQ_API_KEY2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb9210d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def detect_profanity_llm_batch_calls(calls_batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Detect profanity in a batch of calls using a single LLM request.\n",
    "    \n",
    "    Args:\n",
    "        calls_batch: List of call dictionaries with 'call_id' and 'conversation' keys\n",
    "        \n",
    "    Returns:\n",
    "        List of profanity detection results for each call in the batch\n",
    "    \"\"\"\n",
    "    # Setup LLM\n",
    "    llm = ChatGroq(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        temperature=0.0,\n",
    "        max_retries=3,\n",
    "        api_key=os.environ.get(\"GROQ_API_KEY3\"),\n",
    "    )\n",
    "    \n",
    "    # Build batch prompt\n",
    "    prompt_text = (\n",
    "        \"# Role: Expert content moderator for profanity detection\\n\"\n",
    "        \"# Task: Detect profanity in debt collection call utterances\\n\\n\"\n",
    "        \"# Rules:\\n\"\n",
    "        \"- Flag direct profanity and offensive language (f*ck, sh*t, damn, hell, b*tch, a**hole, etc.)\\n\"\n",
    "        \"- Include mild profanity (damn, hell, crap) and strong profanity (f-word, s-word)\\n\"\n",
    "        \"- Consider words like 'screw you', 'pissed off', 'bullsh*t' as profanity\\n\"\n",
    "        \"- Do NOT flag normal business language, frustration without swearing, or polite speech\\n\"\n",
    "        \"- List the exact profane words detected\\n\\n\"\n",
    "        \"# Examples:\\n\"\n",
    "        \"- 'This is f*cking ridiculous' -> has_profanity: true, profane_words: ['fucking']\\n\"\n",
    "        \"- 'I'm really frustrated' -> has_profanity: false, profane_words: []\\n\"\n",
    "        \"- 'What the hell is going on?' -> has_profanity: true, profane_words: ['hell']\\n\"\n",
    "        \"- 'You're being unreasonable' -> has_profanity: false, profane_words: []\\n\\n\"\n",
    "        \"# Output Format: Return ONLY valid JSON array:\\n\"\n",
    "        \"[\\n\"\n",
    "        \"  {\\n\"\n",
    "        \"    \\\"call_id\\\": \\\"string\\\",\\n\"\n",
    "        \"    \\\"utterances\\\": [\\n\"\n",
    "        \"      {\\\"utterance_number\\\": int, \\\"has_profanity\\\": bool, \\\"profane_words\\\": [\\\"word1\\\"]}\\n\"\n",
    "        \"    ]\\n\"\n",
    "        \"  }\\n\"\n",
    "        \"]\\n\\n\"\n",
    "        \"Calls to analyze:\\n\"\n",
    "    )\n",
    "\n",
    "    for idx, call in enumerate(calls_batch, 1):\n",
    "        prompt_text += f\"\\nCall {idx} ID: {call['call_id']}\\n\"\n",
    "        for i, utt in enumerate(call['conversation'], 1):\n",
    "            speaker = utt.get('speaker', 'unknown').capitalize()\n",
    "            text = utt.get('text', '').replace('\\n', ' ')\n",
    "            prompt_text += f\"{i}. [{speaker}] {text}\\n\"\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke([(\"system\", prompt_text)])\n",
    "        content = response.content.strip()\n",
    "        result = json.loads(content)\n",
    "        return result if isinstance(result, list) else []\n",
    "    except:\n",
    "        # Fallback: no profanity detected\n",
    "        return [\n",
    "            {\n",
    "                \"call_id\": call['call_id'],\n",
    "                \"utterances\": [\n",
    "                    {\"utterance_number\": i, \"has_profanity\": False, \"profane_words\": []} \n",
    "                    for i in range(1, len(call['conversation']) + 1)\n",
    "                ]\n",
    "            }\n",
    "            for call in calls_batch\n",
    "        ]\n",
    "\n",
    "\n",
    "def process_conversations_llm_batch_calls(conversations: List[Dict[str, Any]], \n",
    "                                        batch_size: int = 25) -> Dict[str, Dict[str, Set[str]]]:\n",
    "    \"\"\"\n",
    "    Process all conversations in batches to detect profanity.\n",
    "    \n",
    "    Args:\n",
    "        conversations: List of conversation dictionaries with call_id and conversation data\n",
    "        batch_size: Number of calls to process in each batch\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping call_id to profanity results by speaker:\n",
    "        {\"call_id\": {\"Agent\": set(), \"Customer\": set()}}\n",
    "    \"\"\"\n",
    "    profanity_results = {}\n",
    "\n",
    "    for i in tqdm(range(0, len(conversations), batch_size), desc=\"Processing batches\"):\n",
    "        batch_calls = conversations[i:i + batch_size]\n",
    "        batch_detections = detect_profanity_llm_batch_calls(batch_calls)\n",
    "\n",
    "        for call_res in batch_detections:\n",
    "            call_id = call_res[\"call_id\"]\n",
    "            agent_profane = set()\n",
    "            customer_profane = set()\n",
    "            \n",
    "            # Find corresponding conversation\n",
    "            call_conversation = next((c for c in batch_calls if c['call_id'] == call_id), None)\n",
    "            if not call_conversation:\n",
    "                continue\n",
    "            \n",
    "            # Process utterance results\n",
    "            for utt_res in call_res.get(\"utterances\", []):\n",
    "                if not utt_res.get(\"has_profanity\", False):\n",
    "                    continue\n",
    "                    \n",
    "                utt_idx = utt_res[\"utterance_number\"] - 1\n",
    "                if utt_idx >= len(call_conversation['conversation']):\n",
    "                    continue\n",
    "                    \n",
    "                speaker = call_conversation['conversation'][utt_idx].get('speaker', '').lower()\n",
    "                words = utt_res.get(\"profane_words\", [])\n",
    "                \n",
    "                if speaker == \"agent\":\n",
    "                    agent_profane.update(words)\n",
    "                elif speaker in [\"customer\", \"borrower\"]:\n",
    "                    customer_profane.update(words)\n",
    "\n",
    "            profanity_results[call_id] = {\n",
    "                \"Agent\": agent_profane,\n",
    "                \"Customer\": customer_profane,\n",
    "            }\n",
    "\n",
    "    return profanity_results\n",
    "\n",
    "\n",
    "def display_results(results: Dict[str, Dict[str, Set[str]]]) -> None:\n",
    "    \"\"\"\n",
    "    Display profanity detection results with summary statistics.\n",
    "    \n",
    "    Args:\n",
    "        results: Dictionary mapping call_id to profanity results by speaker\n",
    "    \"\"\"\n",
    "    # Print individual results\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"PROFANITY DETECTION RESULTS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    calls_with_profanity = 0\n",
    "    for call_id, profs in results.items():\n",
    "        agent_words = sorted(profs['Agent'])\n",
    "        customer_words = sorted(profs['Customer'])\n",
    "        \n",
    "        if agent_words or customer_words:\n",
    "            calls_with_profanity += 1\n",
    "            print(f\"\\nCall ID: {call_id}\")\n",
    "            if agent_words:\n",
    "                print(f\"  Agent: {agent_words}\")\n",
    "            if customer_words:\n",
    "                print(f\"  Customer: {customer_words}\")\n",
    "    \n",
    "    # Print summary statistics\n",
    "    total_calls = len(results)\n",
    "    agent_calls = sum(1 for data in results.values() if data['Agent'])\n",
    "    customer_calls = sum(1 for data in results.values() if data['Customer'])\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total calls: {total_calls}\")\n",
    "    print(f\"Calls with profanity: {calls_with_profanity}\")\n",
    "    print(f\"Agent profanity in {agent_calls} calls ({agent_calls/total_calls:.1%})\")\n",
    "    print(f\"Customer profanity in {customer_calls} calls ({customer_calls/total_calls:.1%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb4b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 10/10 [09:44<00:00, 58.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "PROFANITY DETECTION RESULTS\n",
      "==================================================\n",
      "\n",
      "Call ID: 3e6dde01-1a46-42b4-92dd-0a211185e660\n",
      "  Customer: ['damn', 'f***', 'hell']\n",
      "\n",
      "Call ID: d7bbea61-d739-43fb-a198-ced1b59f9491\n",
      "  Customer: ['fuck', 'hell', 'shit']\n",
      "\n",
      "Call ID: 9505f0e7-5404-4f50-a497-35a9e899197c\n",
      "  Agent: ['crap', 'damn', 'hell']\n",
      "  Customer: ['freaking']\n",
      "\n",
      "Call ID: d071bb49-40f8-4bae-8c6d-cfc0d4a011d5\n",
      "  Customer: ['bullshit', 'crap', 'damn', 'hell']\n",
      "\n",
      "Call ID: 8598c6d9-a767-4120-af0a-5490357c72f3\n",
      "  Customer: ['a**', 'crap', 'damn', 'f***']\n",
      "\n",
      "Call ID: b70866a2-2f46-4784-992b-74d6dc60806e\n",
      "  Customer: ['damn', 'f***', 'hell', 'pissing', 'screw', 'shit']\n",
      "\n",
      "Call ID: 216fd3c8-1a80-484d-8792-464771794d9e\n",
      "  Customer: ['f***', 'hell']\n",
      "\n",
      "Call ID: 4f05aaff-585f-485f-90a1-60d027ec6e46\n",
      "  Agent: ['damn', 'hell', 'shit']\n",
      "\n",
      "Call ID: ab6ec93c-09e1-4b88-8777-574ceb28cd05\n",
      "  Customer: ['crap', 'damn', 'hell', 'screw']\n",
      "\n",
      "Call ID: 52ddb4a0-0599-4e18-a961-ac4b67da8d5e\n",
      "  Agent: ['hell']\n",
      "\n",
      "Call ID: 50abe040-847c-47e1-962f-a00d7ff2cfe4\n",
      "  Agent: ['crap', 'damn']\n",
      "\n",
      "Call ID: bf973b43-76ec-41a6-af68-a3b4bc4b69b3\n",
      "  Agent: ['damn', 'hell', 'shit']\n",
      "\n",
      "Call ID: b8628a31-ef89-4218-b2a2-3058dbc4b106\n",
      "  Customer: ['crap', 'damn', 'hell', 'screw']\n",
      "\n",
      "Call ID: 5e231fa2-03d8-4e70-9918-da45193472a9\n",
      "  Agent: ['damn', 'hell']\n",
      "\n",
      "Call ID: e835306a-d904-4271-8a11-5a50ce98ed90\n",
      "  Customer: ['bullsh*t', 'crap', 'damn', 'hell']\n",
      "\n",
      "Call ID: 3e77de75-66b9-4b74-a993-1c25b6850bc9\n",
      "  Customer: ['bullshit', 'crap', 'hell']\n",
      "\n",
      "Call ID: c67274cc-d920-467a-80cc-476c9dd280d4\n",
      "  Agent: ['ass', 'dumbass', 'hell', 'shit']\n",
      "\n",
      "Call ID: 29489f77-b8e0-462c-9286-9216d59890f1\n",
      "  Agent: ['damn', 'shit']\n",
      "\n",
      "Call ID: 928acb70-fa80-4532-a0c0-2234bf236e17\n",
      "  Agent: ['hell']\n",
      "\n",
      "Call ID: 8ae8018c-15b3-46f6-9713-f956505735ec\n",
      "  Customer: ['bullsh*t', 'crap', 'f***', 'hell']\n",
      "\n",
      "Call ID: 584fd5cd-adaa-4315-bf67-ad56d02d135e\n",
      "  Customer: ['crap', 'f***', 'f******', 'hell', 's***']\n",
      "\n",
      "Call ID: 2f279983-ea96-4c10-a09d-4b607de21a38\n",
      "  Agent: ['crap', 'damn', 'hell']\n",
      "\n",
      "Call ID: 214c92cc-3141-404d-8224-c1b05acc345c\n",
      "  Agent: ['crap', 'hell']\n",
      "\n",
      "Call ID: ecb08af4-0279-4178-a062-b82de0c701fb\n",
      "  Customer: ['f***', 'f***ing', 'f**k', 'hell', 's**t']\n",
      "\n",
      "Call ID: 966d60ed-9111-4e44-876d-6fcc3d78773e\n",
      "  Agent: ['ass', 'hell', 'shit']\n",
      "\n",
      "Call ID: 23091fb3-8e07-4d4c-8575-227e3467e73a\n",
      "  Agent: ['ass', 'f***ing', 'hell', 'shitload']\n",
      "\n",
      "==================================================\n",
      "SUMMARY\n",
      "==================================================\n",
      "Total calls: 250\n",
      "Calls with profanity: 26\n",
      "Agent profanity in 13 calls (5.2%)\n",
      "Customer profanity in 14 calls (5.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"../data/All_Conversations\"\n",
    "\n",
    "conversations = load_conversations(DATA_DIR)\n",
    "\n",
    "# Process conversations in batches\n",
    "results = process_conversations_llm_batch_calls(conversations, batch_size=25)\n",
    "\n",
    "# Display results\n",
    "display_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prodigal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
